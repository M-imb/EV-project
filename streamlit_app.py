import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from catboost import CatBoostRegressor
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.stattools import adfuller
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.api import ExponentialSmoothing
from prophet import Prophet
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
import pyarrow

import warnings
warnings.filterwarnings('ignore')

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏ ---
st.set_page_config(page_title="üìä –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ —ç–ª–µ–∫—Ç—Ä–æ–º–æ–±–∏–ª–µ–π", layout="wide")
st.title("üìä EV Project - –ê–Ω–∞–ª–∏–∑ –∏ –ø—Ä–æ–≥–Ω–æ–∑")
st.write("## –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö")

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ---
df = pd.read_parquet("Electric_Vehicle_Population_Data.parquet", engine="pyarrow")
# --- –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è ---
df.rename(columns={
    'Model Year': 'year',
    'Make': 'manufacturer',
    'Model': 'model',
    'Electric Vehicle Type': 'ev_type',
    'Electric Range': 'ev_range',
    'Clean Alternative Fuel Vehicle (CAFV) Eligibility': 'cafv_eligible',
    'Postal Code': 'postal_code',
    'City': 'city',
    'State': 'state',
    'County': 'county',
    'Electric Utility': 'utility'
}, inplace=True)

df.drop(columns=[
    'VIN (1-10)',
    'Base MSRP',
    'Legislative District',
    'DOL Vehicle ID',
    'Vehicle Location',
    '2020 Census Tract'
], inplace=True, errors='ignore')

df['year'] = pd.to_numeric(df['year'], errors='coerce')
df.dropna(subset=['year'], inplace=True)
df['year'] = df['year'].astype(int)

# --- –ê–≥—Ä–µ–≥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞ ---
ts_df = df.groupby('year').size().reset_index(name='vehicle_count')
ts_df['year'] = pd.to_datetime(ts_df['year'], format='%Y')
ts_df.set_index('year', inplace=True)
ts_df = ts_df.asfreq('YS').fillna(0)

# --- –í–∫–ª–∞–¥–∫–∏ ---
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "üìà –û–±—â–∏–π –æ–±–∑–æ—Ä",
    "üè≠ –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–∏",
    "üöó –ú–æ–¥–µ–ª–∏",
    "‚è≥ –ü—Ä–æ–≥–Ω–æ–∑ Prophet",
    "üìä –í—Ä–µ–º–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏–∑",
    "üß™ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π"
])

# --- –í–∫–ª–∞–¥–∫–∞ 1: –û–±—â–∏–π –æ–±–∑–æ—Ä ---
with tab1:
    st.subheader("–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ ETL")
    st.write(df.shape)
    st.subheader("–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫")
    st.dataframe(df.head())
    st.subheader("–î–∏–Ω–∞–º–∏–∫–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–π –ø–æ –≥–æ–¥–∞–º")
    fig, ax = plt.subplots()
    ts_df['vehicle_count'].plot(ax=ax, marker='o')
    ax.set_ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ EV")
    ax.set_xlabel("–ì–æ–¥")
    st.pyplot(fig)

# --- –í–∫–ª–∞–¥–∫–∞ 2: –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–∏ ---
with tab2:
    st.subheader("–¢–æ–ø‚Äë10 –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–µ–π")
    fig, ax = plt.subplots()
    manufacturer_counts = df['manufacturer'].value_counts().head(10)
    ax.barh(manufacturer_counts.index, manufacturer_counts.values)
    ax.set_xlabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ")
    ax.set_ylabel("–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å")
    st.pyplot(fig)

# --- –í–∫–ª–∞–¥–∫–∞ 3: –ú–æ–¥–µ–ª–∏ ---
with tab3:
    st.subheader("–¢–æ–ø‚Äë10 –º–æ–¥–µ–ª–µ–π")
    st.bar_chart(df['model'].value_counts().head(10))
    st.subheader("–¢–æ–ø‚Äë5 –∫–æ–º–±–∏–Ω–∞—Ü–∏–π '–ú–∞—Ä–∫–∞-–ú–æ–¥–µ–ª—å'")
    st.write(df.groupby(['manufacturer', 'model']).size().nlargest(5))

# --- –í–∫–ª–∞–¥–∫–∞ 4: –ü—Ä–æ–≥–Ω–æ–∑ Prophet ---
with tab4:
    st.subheader("–ü—Ä–æ–≥–Ω–æ–∑ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ EV —Å –ø–æ–º–æ—â—å—é Prophet")
    prophet_df = ts_df.reset_index().rename(columns={'year': 'ds', 'vehicle_count': 'y'})
    model = Prophet(yearly_seasonality=True, daily_seasonality=False)
    model.fit(prophet_df)
    future = model.make_future_dataframe(periods=5, freq='Y')
    forecast = model.predict(future)
    st.pyplot(model.plot(forecast))
    st.pyplot(model.plot_components(forecast))

# --- –í–∫–ª–∞–¥–∫–∞ 5: –í—Ä–µ–º–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏–∑ ---
with tab5:
    st.subheader("–î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞")
    decomposition = seasonal_decompose(ts_df['vehicle_count'], model='additive', period=1)
    fig, axes = plt.subplots(4, 1, figsize=(10, 6), sharex=True)
    decomposition.observed.plot(ax=axes[0], title='–ù–∞–±–ª—é–¥–∞–µ–º—ã–π —Ä—è–¥')
    decomposition.trend.plot(ax=axes[1], title='–¢—Ä–µ–Ω–¥')
    decomposition.seasonal.plot(ax=axes[2], title='–°–µ–∑–æ–Ω–Ω–æ—Å—Ç—å')
    decomposition.resid.plot(ax=axes[3], title='–û—Å—Ç–∞—Ç–∫–∏')
    plt.tight_layout()
    st.pyplot(fig)

    st.subheader("–¢–µ—Å—Ç –î–∏–∫–∏‚Äì–§—É–ª–ª–µ—Ä–∞")
    result = adfuller(ts_df['vehicle_count'])
    st.write(f"ADF Statistic: {result[0]:.4f}")
    st.write(f"p-value: {result[1]:.4f}")
    st.write("Critical Values:", result[4])
    if result[1] <= 0.05:
        st.success("–†—è–¥ —è–≤–ª—è–µ—Ç—Å—è —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–º (p-value <= 0.05)")
    else:
        st.warning("–†—è–¥ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–º (p-value > 0.05)")

    st.subheader("ACF –∏ PACF")
    fig, axes = plt.subplots(2, 1, figsize=(10, 6))
    plot_acf(ts_df['vehicle_count'], ax=axes[0])
    axes[0].set_title('–ê–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è (ACF)')
    plot_pacf(ts_df['vehicle_count'], ax=axes[1])
    axes[1].set_title('–ß–∞—Å—Ç–∏—á–Ω–∞—è –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è (PACF)')
    plt.tight_layout()
    st.pyplot(fig)

# --- –í–∫–ª–∞–¥–∫–∞ 6: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π ---
with tab6:
    st.subheader("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è")

    # --- –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö ---
    train_size = int(len(ts_df) * 0.8)
    ts_train = ts_df.iloc[:train_size]
    ts_test = ts_df.iloc[train_size:]

    metrics_df = pd.DataFrame(columns=['Model', 'RMSE', 'MAE', 'R2'])
    predictions = {}

    def evaluate_model(model_name, y_true, y_pred):
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
        mae = mean_absolute_error(y_true, y_pred)
        r2 = r2_score(y_true, y_pred)
        return pd.Series([model_name, rmse, mae, r2], index=metrics_df.columns)

    # --- 1. –†–µ–≥—Ä–µ—Å—Å–∏–∏ ---
    # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –æ—à–∏–±–∫–∞ 'AttributeError'
    X = ts_df.index.year.values.reshape(-1, 1)
    y = ts_df['vehicle_count'].values
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

    lr_model = LinearRegression().fit(X_train, y_train)
    rf_model = RandomForestRegressor(random_state=42).fit(X_train, y_train)
    cb_model = CatBoostRegressor(random_state=42, verbose=0).fit(X_train, y_train)
    
    lr_pred = lr_model.predict(X_test)
    rf_pred = rf_model.predict(X_test)
    cb_pred = cb_model.predict(X_test)
    
    metrics_df = pd.concat([metrics_df, evaluate_model('Linear Regression', y_test, lr_pred).to_frame().T, evaluate_model('Random Forest', y_test, rf_pred).to_frame().T, evaluate_model('CatBoost', y_test, cb_pred).to_frame().T], ignore_index=True)
    predictions['Linear Regression'] = (ts_test.index, lr_pred)
    predictions['Random Forest'] = (ts_test.index, rf_pred)
    predictions['CatBoost'] = (ts_test.index, cb_pred)

    # --- 2. ARIMA ---
    arima_model = ARIMA(ts_train['vehicle_count'], order=(1, 1, 1)).fit()
    arima_pred = arima_model.forecast(len(ts_test))
    metrics_df = pd.concat([metrics_df, evaluate_model('ARIMA', ts_test['vehicle_count'], arima_pred).to_frame().T], ignore_index=True)
    predictions['ARIMA'] = (ts_test.index, arima_pred)

    # --- 3. LSTM ---
    # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –æ—à–∏–±–∫–∞ 'AttributeError' –∏ –∏–∑–º–µ–Ω–µ–Ω—ã —Ä–∞–∑–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö
    scaler = MinMaxScaler(feature_range=(0, 1))
    scaled_data = scaler.fit_transform(ts_df[['vehicle_count']])
    train_data = scaled_data[:train_size]
    test_data = scaled_data[train_size:]
    
    seq_length = 3
    
    def create_sequences(data, seq_length):
        X, y = [], []
        for i in range(len(data) - seq_length):
            X.append(data[i:i + seq_length])
            y.append(data[i + seq_length])
        return np.array(X), np.array(y)
    
    X_train_lstm, y_train_lstm = create_sequences(train_data, seq_length)
    X_test_lstm, y_test_lstm = create_sequences(test_data, seq_length)

    model_lstm = Sequential()
    model_lstm.add(LSTM(50, activation='relu', input_shape=(seq_length, 1)))
    model_lstm.add(Dense(1))
    model_lstm.compile(optimizer='adam', loss='mean_squared_error')
    model_lstm.fit(X_train_lstm, y_train_lstm, epochs=100, batch_size=1, verbose=0)
    
    test_predictions_lstm = model_lstm.predict(X_test_lstm)
    test_predictions_lstm = scaler.inverse_transform(test_predictions_lstm)

    metrics_df = pd.concat([metrics_df, evaluate_model('LSTM', scaler.inverse_transform(y_test_lstm), test_predictions_lstm.flatten()).to_frame().T], ignore_index=True)
    predictions['LSTM'] = (ts_test.index[seq_length:], test_predictions_lstm.flatten())
    
    # --- 4. Prophet ---
    prophet_df = ts_df.reset_index().rename(columns={'year': 'ds', 'vehicle_count': 'y'})
    prophet_train = prophet_df.iloc[:train_size]
    prophet_test = prophet_df.iloc[train_size:]
    
    m = Prophet().fit(prophet_train)
    future = m.make_future_dataframe(periods=len(prophet_test), freq='YS')
    forecast = m.predict(future)
    prophet_pred = forecast['yhat'].iloc[train_size:].values
    
    metrics_df = pd.concat([metrics_df, evaluate_model('Prophet', prophet_test['y'].values, prophet_pred).to_frame().T], ignore_index=True)
    predictions['Prophet'] = (prophet_test['ds'].values, prophet_pred)

    # --- 5. Holt-Winters ---
    fit_hw = ExponentialSmoothing(ts_train['vehicle_count'], trend='add').fit()
    hw_pred = fit_hw.forecast(len(ts_test))
    metrics_df = pd.concat([metrics_df, evaluate_model('Holt-Winters', ts_test['vehicle_count'], hw_pred).to_frame().T], ignore_index=True)
    predictions['Holt-Winters'] = (ts_test.index, hw_pred)

    # --- 6. ETS ---
    fit_ets = ExponentialSmoothing(ts_train['vehicle_count']).fit()
    ets_pred = fit_ets.forecast(len(ts_test))
    metrics_df = pd.concat([metrics_df, evaluate_model('ETS', ts_test['vehicle_count'], ets_pred).to_frame().T], ignore_index=True)
    predictions['ETS'] = (ts_test.index, ets_pred)
    
    st.subheader("–°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –º–µ—Ç—Ä–∏–∫ –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π")
    st.dataframe(metrics_df.sort_values(by='R2', ascending=False).round(2))
    
    # --- –ò—Ç–æ–≥–æ–≤—ã–π –≥—Ä–∞—Ñ–∏–∫ —Å–æ –≤—Å–µ–º–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞–º–∏ ---
    fig, ax = plt.subplots(figsize=(15, 8))
    ax.plot(ts_df.index, ts_df['vehicle_count'], label='–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ', color='black', marker='o')
    
    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
    for model_name, (index, pred) in predictions.items():
        if model_name == 'LSTM': # Special handling for LSTM due to sequence length
            ax.plot(index, pred, label=model_name, linestyle='--')
        elif model_name == 'Prophet':
            ax.plot(index, pred, label=model_name, linestyle='--')
        else:
            ax.plot(index, pred, label=model_name, linestyle='--')
            
    ax.set_title('–ò—Ç–æ–≥–æ–≤–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π')
    ax.set_xlabel('–ì–æ–¥')
    ax.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–¥–∞–Ω–Ω—ã—Ö –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π')
    ax.legend()
    ax.grid(True)
    st.pyplot(fig)
