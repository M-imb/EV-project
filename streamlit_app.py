import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
import category_encoders as ce
import plotly.express as px
import plotly.graph_objects as go
import matplotlib.pyplot as plt
from catboost import CatBoostRegressor
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.stattools import adfuller, acf, pacf
from statsmodels.tsa.arima.model import ARIMA
from prophet import Prophet
import warnings
warnings.filterwarnings('ignore')

st.set_page_config(page_title="üìä –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ —ç–ª–µ–∫—Ç—Ä–æ–º–æ–±–∏–ª–µ–π", layout="wide")
st.title("üìä EV Project - –ê–Ω–∞–ª–∏–∑ –∏ –ø—Ä–æ–≥–Ω–æ–∑")
st.write("## –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö")

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ---
st.set_page_config(page_title="üìä –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ —ç–ª–µ–∫—Ç—Ä–æ–º–æ–±–∏–ª–µ–π", layout="wide")
st.title("üìä EV Project - –ê–Ω–∞–ª–∏–∑ –∏ –ø—Ä–æ–≥–Ω–æ–∑")
st.write("## –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö")

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ---
df = pd.read_parquet("Electric_Vehicle_Population_Data.parquet", engine="pyarrow")

# --- –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è ---
df.rename(columns={
    'Model Year': 'year',
    'Make': 'manufacturer',
    'Model': 'model',
    'Electric Vehicle Type': 'ev_type',
    'Electric Range': 'ev_range',
    'Clean Alternative Fuel Vehicle (CAFV) Eligibility': 'cafv_eligible',
    'Postal Code': 'postal_code',
    'City': 'city',
    'State': 'state',
    'County': 'county',
    'Electric Utility': 'utility'
}, inplace=True)

df.drop(columns=[
    'VIN (1-10)',
    'Base MSRP',
    'Legislative District',
    'DOL Vehicle ID',
    'Vehicle Location',
    '2020 Census Tract'
], inplace=True, errors='ignore')

df['year'] = pd.to_numeric(df['year'], errors='coerce')
df.dropna(subset=['year'], inplace=True)
df['year'] = df['year'].astype(int)

if df.empty:
    st.error("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    st.stop()
    

# --- –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ ---
ts_df = df.groupby('year').size().reset_index(name='vehicle_count')
ts_df['year'] = pd.to_datetime(ts_df['year'], format='%Y')
ts_df.set_index('year', inplace=True)
ts_df = ts_df.asfreq('YS').fillna(0)

# --- –í–∫–ª–∞–¥–∫–∏ ---
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "üìà –û–±—â–∏–π –æ–±–∑–æ—Ä",
    "üè≠ –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–∏",
    "üöó –ú–æ–¥–µ–ª–∏",
    "‚è≥ –ü—Ä–æ–≥–Ω–æ–∑",
    "üìä –í—Ä–µ–º–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏–∑"
])

# --- –í–∫–ª–∞–¥–∫–∞ 1 ---
with tab1:
    st.subheader("–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ ETL")
    st.write(df.shape)
    st.subheader("–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫")
    st.dataframe(df.head())
    st.subheader("–î–∏–Ω–∞–º–∏–∫–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–π –ø–æ –≥–æ–¥–∞–º")
    fig, ax = plt.subplots()
    ts_df['vehicle_count'].plot(ax=ax, marker='o')
    ax.set_ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ EV")
    ax.set_xlabel("–ì–æ–¥")
    st.pyplot(fig)

# --- –í–∫–ª–∞–¥–∫–∞ 2 ---
with tab2:
    st.subheader("–¢–æ–ø‚Äë5 –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–µ–π")
    st.bar_chart(df['manufacturer'].value_counts().head(5))
    st.subheader("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—è–º")
    fig, ax = plt.subplots(figsize=(8, 4))
    sns.countplot(y='manufacturer', data=df, order=df['manufacturer'].value_counts().index[:10], ax=ax)
    st.pyplot(fig)

# --- –í–∫–ª–∞–¥–∫–∞ 3 ---
with tab3:
    st.subheader("–¢–æ–ø‚Äë5 –º–æ–¥–µ–ª–µ–π")
    st.bar_chart(df['model'].value_counts().head(5))
    st.subheader("–¢–æ–ø‚Äë5 –∫–æ–º–±–∏–Ω–∞—Ü–∏–π '–ú–∞—Ä–∫–∞‚Äë–ú–æ–¥–µ–ª—å'")
    st.write(df.groupby(['manufacturer', 'model']).size().nlargest(5))

# --- –í–∫–ª–∞–¥–∫–∞ 4 ---
with tab4:
    st.subheader("–ü—Ä–æ–≥–Ω–æ–∑ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ EV —Å –ø–æ–º–æ—â—å—é Prophet")
    prophet_df = ts_df.reset_index().rename(columns={'year': 'ds', 'vehicle_count': 'y'})
    model = Prophet(yearly_seasonality=True, daily_seasonality=False)
    model.fit(prophet_df)
    future = model.make_future_dataframe(periods=5, freq='Y')
    forecast = model.predict(future)
    st.pyplot(model.plot(forecast))
    st.pyplot(model.plot_components(forecast))

# --- –í–∫–ª–∞–¥–∫–∞ 5: –í—Ä–µ–º–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏–∑ ---
with tab5:
    st.subheader("–î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞")
    decomposition = seasonal_decompose(ts_df['vehicle_count'], model='additive', period=1)
    fig, axes = plt.subplots(4, 1, figsize=(10, 6), sharex=True)
    decomposition.observed.plot(ax=axes[0], title='–ù–∞–±–ª—é–¥–∞–µ–º—ã–π —Ä—è–¥')
    decomposition.trend.plot(ax=axes[1], title='–¢—Ä–µ–Ω–¥')
    decomposition.seasonal.plot(ax=axes[2], title='–°–µ–∑–æ–Ω–Ω–æ—Å—Ç—å')
    decomposition.resid.plot(ax=axes[3], title='–û—Å—Ç–∞—Ç–∫–∏')
    plt.tight_layout()
    st.pyplot(fig)

    st.subheader("–¢–µ—Å—Ç –î–∏–∫–∏‚Äì–§—É–ª–ª–µ—Ä–∞")
    result = adfuller(ts_df['vehicle_count'])
    st.write(f"ADF Statistic: {result[0]:.4f}")
    st.write(f"p-value: {result[1]:.4f}")
    st.write("Critical Values:", result[4])
    if result[1] <= 0.05:
        st.success("–†—è–¥ —è–≤–ª—è–µ—Ç—Å—è —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–º (p-value <= 0.05)")
    else:
        st.warning("–†—è–¥ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–º (p-value > 0.05)")

    st.subheader("ACF –∏ PACF")
    fig, axes = plt.subplots(2, 1, figsize=(10, 6))
    plot_acf(ts_df['vehicle_count'], ax=axes[0])
    axes[0].set_title('–ê–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è (ACF)')
    plot_pacf(ts_df['vehicle_count'], ax=axes[1])
    axes[1].set_title('–ß–∞—Å—Ç–∏—á–Ω–∞—è –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è (PACF)')
    plt.tight_layout()
    st.pyplot(fig)

    st.info("ACF-–≥—Ä–∞—Ñ–∏–∫ –º–µ–¥–ª–µ–Ω–Ω–æ –∑–∞—Ç—É—Ö–∞–µ—Ç ‚Üí –Ω–∞–ª–∏—á–∏–µ —Ç—Ä–µ–Ω–¥–∞. PACF –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–∏–ª—å–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –Ω–∞ –ø–µ—Ä–≤—ã—Ö –ª–∞–≥–∞—Ö.")

    st.subheader("–û—Ü–µ–Ω–∫–∞ Prophet (train/test split)")
    prophet_df = ts_df.reset_index().rename(columns={'year': 'ds', 'vehicle_count': 'y'})
    train_size = int(len(prophet_df) * 0.7)
    prophet_train = prophet_df.iloc[:train_size]
    prophet_test = prophet_df.iloc[train_size:]
    m = Prophet()
    m.fit(prophet_train)
    future = m.make_future_dataframe(periods=len(prophet_test), freq='YS')
    forecast = m.predict(future)
    prophet_pred = forecast['yhat'].iloc[train_size:]
    rmse = np.sqrt(mean_squared_error(prophet_test['y'], prophet_pred))
    mae = mean_absolute_error(prophet_test['y'], prophet_pred)
    r2 = r2_score(prophet_test['y'], prophet_pred)
    st.write(pd.DataFrame([[ 'Prophet', rmse, mae, r2 ]], columns=['Model','RMSE','MAE','R2']))
    st.pyplot(m.plot(forecast))
    st.pyplot(m.plot_components(forecast))

# --- –í–∫–ª–∞–¥–∫–∞ 6: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π ---
with tab6:
    st.subheader("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è")

    # --- –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö ---
    train_size = int(len(ts_df) * 0.7)
    ts_train = ts_df.iloc[:train_size]
    ts_test = ts_df.iloc[train_size:]

    metrics_df = pd.DataFrame(columns=['Model', 'RMSE', 'MAE', 'R2'])

    def evaluate_model(model_name, y_true, y_pred):
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
        mae = mean_absolute_error(y_true, y_pred)
        r2 = r2_score(y_true, y_pred)
        return pd.Series([model_name, rmse, mae, r2], index=metrics_df.columns)

    # --- 1. –†–µ–≥—Ä–µ—Å—Å–∏–∏ ---
    X = ts_df.index.year.values.reshape(-1, 1)
    y = ts_df['vehicle_count'].values
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)

    lr_model = LinearRegression()
    rf_model = RandomForestRegressor(random_state=42)
    cb_model = CatBoostRegressor(random_state=42, verbose=0)

    lr_model.fit(X_train, y_train)
    rf_model.fit(X_train, y_train)
    cb_model.fit(X_train, y_train)

    lr_pred = lr_model.predict(X_test)
    rf_pred = rf_model.predict(X_test)
    cb_pred = cb_model.predict(X_test)

    metrics_df = pd.concat([
        metrics_df,
        evaluate_model('Linear Regression', y_test, lr_pred).to_frame().T,
        evaluate_model('Random Forest', y_test, rf_pred).to_frame().T,
        evaluate_model('CatBoost', y_test, cb_pred).to_frame().T
    ], ignore_index=True)

    # --- 2. ARIMA ---
    arima_model = ARIMA(ts_train['vehicle_count'], order=(1, 1, 1))
    arima_fit = arima_model.fit()
    arima_pred = arima_fit.forecast(len(ts_test))
    metrics_df = pd.concat([metrics_df, evaluate_model('ARIMA', ts_test['vehicle_count'], arima_pred).to_frame().T], ignore_index=True)

    # --- 3. LSTM ---
    scaler = MinMaxScaler(feature_range=(0, 1))
    scaled_data = scaler.fit_transform(ts_df)
    train_data = scaled_data[:train_size]
    test_data = scaled_data[train_size:]

    def create_sequences(data, seq_length):
        X, y = [], []
        for i in range(len(data) - seq_length):
            X.append(data[i:i + seq_length])
            y.append(data[i + seq_length])
        return np.array(X), np.array(y)

    seq_length = 3
    X_train_lstm, y_train_lstm = create_sequences(train_data, seq_length)
    X_test_lstm, y_test_lstm = create_sequences(test_data, seq_length)

    model_lstm = Sequential()
    model_lstm.add(LSTM(50, activation='relu', input_shape=(seq_length, 1)))
    model_lstm.add(Dense(1))
    model_lstm.compile(optimizer='adam', loss='mean_squared_error')
    model_lstm.fit(X_train_lstm, y_train_lstm, epochs=100, batch_size=1, verbose=0)

    test_predictions_lstm = model_lstm.predict(X_test_lstm)
    test_predictions_lstm = scaler.inverse_transform(test_predictions_lstm)
    y_test_lstm = scaler.inverse_transform(y_test_lstm)

    metrics_df = pd.concat([metrics_df, evaluate_model('LSTM', y_test_lstm, test_predictions_lstm).to_frame().T], ignore_index=True)

    # --- 4. Prophet ---
    prophet_df = ts_df.reset_index().rename(columns={'year': 'ds', 'vehicle_count': 'y'})
    prophet_train = prophet_df.iloc[:train_size]
    prophet_test = prophet_df.iloc[train_size:]

    m = Prophet()
    m.fit(prophet_train)

    future = m.make_future_dataframe(periods=len(prophet_test), freq='YS')
    forecast = m.predict(future)
    prophet_pred = forecast['yhat'].iloc[train_size:]
    metrics_df = pd.concat([metrics_df, evaluate_model('Prophet', prophet_test['y'], prophet_pred).to_frame().T], ignore_index=True)

    # --- –í—ã–≤–æ–¥ –º–µ—Ç—Ä–∏–∫ ---
    st.dataframe(metrics_df.round(2))

    # --- –ì—Ä–∞—Ñ–∏–∫ ---
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.plot(ts_train.index, ts_train['vehicle_count'], label='Train', color='black')
    ax.plot(ts_test.index, ts_test['vehicle_count'], label='Test', color='gray')
    ax.plot(ts_test.index, lr_pred, label='Linear Regression', color='blue')
    ax.plot(ts_test.index, rf_pred, label='Random Forest', color='green')
    ax.plot(ts_test.index, cb_pred, label='CatBoost', color='purple')
    ax.plot(ts_test.index, arima_pred, label='ARIMA', color='red')
    ax.plot(ts_test.index[seq_length:], test_predictions_lstm.flatten(), label='LSTM', color='cyan')
    ax.plot(prophet_test['ds'], prophet_pred, label='Prophet', color='orange')
    ax.set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π')
    ax.set_xlabel('–ì–æ–¥')
    ax.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ EV')
    ax.legend()
    ax.grid(True)
    st.pyplot(fig)

    # --- –í—ã–≤–æ–¥—ã ---
    st.markdown("""
    **–í—ã–≤–æ–¥—ã:**
    1. –†—è–¥ –∏–º–µ–µ—Ç —Å–∏–ª—å–Ω—ã–π –≤–æ—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥ ‚Äî –ø—Ä–æ—Å—Ç—ã–µ –º–æ–¥–µ–ª–∏ (Linear Regression) –µ–≥–æ —É–ª–∞–≤–ª–∏–≤–∞—é—Ç.
    2. CatBoost –∏ Random Forest –ª—É—á—à–µ —Å–ø—Ä–∞–≤–ª—è—é—Ç—Å—è —Å –Ω–µ–ª–∏–Ω–µ–π–Ω–æ—Å—Ç—è–º–∏.
    3. ARIMA —É—á–∏—Ç—ã–≤–∞–µ—Ç —Ç—Ä–µ–Ω–¥ –∏ –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é.
    4. LSTM —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö, –Ω–æ —Ç–æ–∂–µ –¥–∞—ë—Ç –Ω–µ–ø–ª–æ—Ö–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç.
    5. Prophet –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—Ö–æ–¥–∏—Ç —Ç—Ä–µ–Ω–¥—ã –∏ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å, –ø–æ–∫–∞–∑—ã–≤–∞—è –≤—ã—Å–æ–∫—É—é —Ç–æ—á–Ω–æ—Å—Ç—å.
    """)
